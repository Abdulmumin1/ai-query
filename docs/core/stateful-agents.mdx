---
title: "Stateful Agents"
description: "Build persistent, stateful AI agents with built-in storage and WebSocket support"
---

ai-query provides a powerful `Agent` class for building stateful AI applications. Unlike standard LLM calls, **Agents** maintain memory, state, and identity over time.

## Quick Start

```python
from ai_query import Agent, openai

agent = Agent("assistant", model=openai("gpt-4o"))

async with agent:
    response = await agent.chat("Hello!")
    print(response)

    response = await agent.chat("What did I just say?")
    print(response)  # Agent remembers the conversation
```

## 30 Seconds to Your First Agent

```python
from ai_query import Agent, openai

agent = Agent("my-agent", model=openai("gpt-4o"))

async with agent:
    print(await agent.chat("Hello!"))
```

## 60 Seconds to Persistence

```python
from ai_query import Agent, SQLiteStorage, openai

agent = Agent(
    "my-agent",
    model=openai("gpt-4o"),
    storage=SQLiteStorage("agents.db")
)

async with agent:
    print(await agent.chat("Remember: my favorite color is blue"))

# Later, in a new process...
agent = Agent("my-agent", storage=SQLiteStorage("agents.db"))
async with agent:
    print(await agent.chat("What's my favorite color?"))  # "blue"
```

## Core Concepts

### State & Messages

Every agent has a `state` dictionary and a `messages` list that are automatically persisted.

```python
async with agent:
    # Set state (automatically persisted)
    await agent.set_state({"user_name": "Alice", "preferences": {}})

    # Update state
    await agent.update_state(mood="happy")

    # Access state
    print(agent.state)  # {"user_name": "Alice", "preferences": {}, "mood": "happy"}

    # Access conversation history
    print(agent.messages)

    # Clear conversation
    await agent.clear()
```

### Storage Backends

Choose where your data lives by passing a storage backend:

| Backend | Description | Best For |
|---------|-------------|----------|
| `MemoryStorage()` | RAM-only (default) | Testing, development |
| `SQLiteStorage(path)` | Local file | Single-server apps, prototypes |
| Custom | Redis, DynamoDB, etc. | Production, distributed |

```python
from ai_query import Agent, MemoryStorage, SQLiteStorage

# In-memory (default)
agent = Agent("bot", storage=MemoryStorage())

# SQLite persistence
agent = Agent("bot", storage=SQLiteStorage("agents.db"))
```

### Custom Storage

Implement the `Storage` protocol to use any backend:

```python
from ai_query import Storage

class RedisStorage:
    def __init__(self, url: str):
        self.client = redis.from_url(url)

    async def get(self, key: str) -> Any | None:
        value = await self.client.get(key)
        return json.loads(value) if value else None

    async def set(self, key: str, value: Any) -> None:
        await self.client.set(key, json.dumps(value))

    async def delete(self, key: str) -> None:
        await self.client.delete(key)

    async def keys(self, prefix: str = "") -> list[str]:
        return await self.client.keys(f"{prefix}*")

# Use it
agent = Agent("bot", storage=RedisStorage("redis://localhost"))
```

### Tools

Give your agent capabilities:

```python
from ai_query import Agent, openai, tool, Field

@tool(description="Search the web")
async def search(query: str = Field(description="Search query")) -> str:
    return f"Results for: {query}"

@tool(description="Send an email")
async def send_email(
    to: str = Field(description="Recipient"),
    body: str = Field(description="Email body")
) -> str:
    return f"Email sent to {to}"

agent = Agent(
    "assistant",
    model=openai("gpt-4o"),
    system="You are a helpful assistant with access to search and email.",
    tools={"search": search, "send_email": send_email}
)

async with agent:
    response = await agent.chat("Search for the latest AI news and email a summary to bob@example.com")
```

### Streaming

Stream responses for real-time output:

```python
async with agent:
    async for chunk in agent.stream("Tell me a story"):
        print(chunk, end="", flush=True)
```

### Abort / Cancellation

Cancel long-running operations:

```python
from ai_query import Agent, AbortController, AbortError

controller = AbortController()

try:
    async with agent:
        # Pass signal to chat
        response = await agent.chat(
            "Write a very long essay",
            signal=controller.signal
        )
except AbortError as e:
    print(f"Cancelled: {e.reason}")

# Abort from another task
controller.abort("User cancelled")
```

Use timeout for automatic cancellation:

```python
from ai_query import AbortSignal

async with agent:
    response = await agent.chat(
        "Complex question",
        signal=AbortSignal.timeout(30)  # Auto-cancel after 30s
    )
```

## Lifecycle Hooks

Override lifecycle methods to customize behavior:

```python
class MyAgent(Agent):
    async def on_start(self):
        print(f"Agent {self.id} started")

    async def on_stop(self):
        print(f"Agent {self.id} stopped")

    async def on_connect(self, connection, ctx):
        print(f"Client connected")
        await super().on_connect(connection, ctx)

    async def on_message(self, connection, message):
        response = await self.chat(message)
        await connection.send(response)

    async def on_close(self, connection, code, reason):
        print(f"Client disconnected: {reason}")
        await super().on_close(connection, code, reason)
```

## WebSocket Server

Serve an agent over WebSocket, SSE, and REST:

```python
agent = Agent("assistant", model=openai("gpt-4o"))
agent.serve(port=8080)
```

Endpoints:
- `POST /chat` - Send message, get response (streams to SSE)
- `GET /events` - SSE stream of events
- `WS /ws` - WebSocket connection
- `GET /state` - Get agent state

<Warning>
**Security Note**: `agent.serve()` has no authentication built-in. It's designed for local development and prototyping.

For production, use `AgentServer` which supports:
- Custom authentication middleware
- CORS configuration
- Rate limiting hooks

```python
from ai_query import AgentServer, AgentServerConfig

async def auth_check(request):
    return request.headers.get("X-API-Key") == "secret"

config = AgentServerConfig(
    auth=auth_check,
    allowed_origins=["https://myapp.com"]
)

AgentServer(MyAgent, config=config).serve(port=8080)
```

See [Agent Server](/core/agent-server) for production deployment.
</Warning>

## API Reference

<CardGroup cols={2}>
  <Card title="Agent API" icon="book" href="/api-reference/agent">
    Full methods and properties
  </Card>
  <Card title="Storage Backends" icon="database" href="/api-reference/agent-backends">
    MemoryStorage, SQLiteStorage, and custom
  </Card>
  <Card title="Abort/Cancellation" icon="circle-stop" href="/core/abort">
    AbortController and AbortSignal
  </Card>
</CardGroup>
