---
title: "Serverless Agents"
description: "Deploy agents to AWS Lambda, Vercel, Google Cloud Run, and other serverless platforms"
---

Deploy AI agents to serverless platforms where each request starts fresh. The `handle_request()` method provides a complete lifecycle: load state → process → save state → respond.

## Quick Start

```python
from ai_query import Agent, SQLiteStorage, openai

class SupportAgent(Agent):
    def __init__(self, agent_id: str):
        super().__init__(
            agent_id,
            model=openai("gpt-4o"),
            system="You are a helpful customer support agent.",
            storage=SQLiteStorage("./agents.db"),
            initial_state={"tickets_handled": 0}
        )

    async def handle_invoke(self, payload: dict) -> dict:
        task = payload.get("task")

        if task == "chat":
            response = await self.chat(payload["message"])
            await self.update_state(tickets_handled=self.state.get("tickets_handled", 0) + 1)
            return {"response": response}

        return {"error": f"Unknown task: {task}"}
```

## Platform Examples

<Tabs>
  <Tab title="FastAPI">
```python
# main.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from ai_query import Agent, SQLiteStorage, openai

app = FastAPI()

class SupportAgent(Agent):
    def __init__(self, agent_id: str):
        super().__init__(
            agent_id,
            model=openai("gpt-4o"),
            system="""You are a customer support agent for TechCorp.
            Be helpful, professional, and concise.""",
            storage=SQLiteStorage("./agents.db"),
            initial_state={"conversation_count": 0}
        )

class ChatRequest(BaseModel):
    message: str

class InvokeRequest(BaseModel):
    task: str
    payload: dict = {}

@app.post("/agent/{agent_id}/chat")
async def chat(agent_id: str, request: ChatRequest):
    agent = SupportAgent(agent_id)
    result = await agent.handle_request({
        "action": "chat",
        "message": request.message
    })
    return result

@app.post("/agent/{agent_id}/invoke")
async def invoke(agent_id: str, request: InvokeRequest):
    agent = SupportAgent(agent_id)
    result = await agent.handle_request({
        "action": "invoke",
        "payload": {"task": request.task, **request.payload}
    })
    return result

@app.get("/agent/{agent_id}/state")
async def get_state(agent_id: str):
    agent = SupportAgent(agent_id)
    result = await agent.handle_request({"action": "state"})
    return result

# Run with: uvicorn main:app --reload
```
  </Tab>

  <Tab title="AWS Lambda">
```python
# handler.py
import json
import asyncio
from ai_query import Agent, SQLiteStorage, openai

class OrderAgent(Agent):
    def __init__(self, agent_id: str):
        super().__init__(
            agent_id,
            model=openai("gpt-4o"),
            system="""You are an order management assistant.
            Help customers track orders, process returns, and answer questions.""",
            storage=SQLiteStorage("/mnt/efs/agents.db"),  # EFS mount for persistence
            initial_state={"orders_processed": 0}
        )

    async def handle_invoke(self, payload: dict) -> dict:
        task = payload.get("task")

        if task == "track_order":
            order_id = payload.get("order_id")
            status = await self.lookup_order(order_id)
            return {"order_id": order_id, "status": status}

        if task == "process_return":
            order_id = payload.get("order_id")
            reason = payload.get("reason", "")
            return_id = await self.create_return(order_id, reason)
            return {"return_id": return_id, "status": "initiated"}

        return {"error": f"Unknown task: {task}"}

    async def lookup_order(self, order_id: str) -> dict:
        return {"status": "shipped", "eta": "2024-01-15"}

    async def create_return(self, order_id: str, reason: str) -> str:
        return f"RET-{order_id}"


def handler(event, context):
    path_params = event.get("pathParameters", {})
    agent_id = path_params.get("agent_id", "default")

    body = json.loads(event.get("body", "{}"))
    action = body.get("action", "chat")

    request = {"action": action}
    if action == "chat":
        request["message"] = body.get("message", "")
    elif action == "invoke":
        request["payload"] = body.get("payload", {})

    agent = OrderAgent(agent_id)
    result = asyncio.run(agent.handle_request(request))

    return {
        "statusCode": 200,
        "headers": {
            "Content-Type": "application/json",
            "Access-Control-Allow-Origin": "*"
        },
        "body": json.dumps(result)
    }
```

**SAM Template (template.yaml):**
```yaml
AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31

Resources:
  AgentFunction:
    Type: AWS::Serverless::Function
    Properties:
      Handler: handler.handler
      Runtime: python3.11
      Timeout: 30
      MemorySize: 512
      FileSystemConfigs:
        - Arn: !GetAtt EFSAccessPoint.Arn
          LocalMountPath: /mnt/efs
      Events:
        Chat:
          Type: Api
          Properties:
            Path: /agent/{agent_id}
            Method: post
```
  </Tab>

  <Tab title="Vercel">
```python
# api/agent/[agent_id].py
import json
from http.server import BaseHTTPRequestHandler
import asyncio
from ai_query import Agent, MemoryStorage, openai

class AssistantAgent(Agent):
    def __init__(self, agent_id: str):
        super().__init__(
            agent_id,
            model=openai("gpt-4o"),
            system="You are a helpful assistant.",
            storage=MemoryStorage(),
            initial_state={}
        )

class handler(BaseHTTPRequestHandler):
    def do_POST(self):
        agent_id = self.path.split("/")[-1]

        content_length = int(self.headers.get("Content-Length", 0))
        body = json.loads(self.rfile.read(content_length))

        agent = AssistantAgent(agent_id)
        result = asyncio.run(agent.handle_request({
            "action": body.get("action", "chat"),
            "message": body.get("message", ""),
            "payload": body.get("payload", {})
        }))

        self.send_response(200)
        self.send_header("Content-Type", "application/json")
        self.end_headers()
        self.wfile.write(json.dumps(result).encode())

    def do_GET(self):
        agent_id = self.path.split("/")[-1]
        agent = AssistantAgent(agent_id)
        result = asyncio.run(agent.handle_request({"action": "state"}))

        self.send_response(200)
        self.send_header("Content-Type", "application/json")
        self.end_headers()
        self.wfile.write(json.dumps(result).encode())
```

<Note>
For Vercel with persistence, use a custom storage backend with Vercel KV (Redis) or Vercel Postgres.
</Note>
  </Tab>

  <Tab title="Google Cloud Run">
```python
# main.py
import os
from flask import Flask, request, jsonify
import asyncio
from ai_query import Agent, SQLiteStorage, openai

app = Flask(__name__)

class AnalystAgent(Agent):
    def __init__(self, agent_id: str):
        super().__init__(
            agent_id,
            model=openai("gpt-4o"),
            system="""You are a data analyst assistant.
            Help users understand their data and create insights.""",
            storage=SQLiteStorage("/data/agents.db"),  # Mounted Cloud Storage FUSE
            initial_state={"analyses_run": 0}
        )

    async def handle_invoke(self, payload: dict) -> dict:
        task = payload.get("task")

        if task == "analyze":
            data = payload.get("data", [])
            prompt = f"Analyze this data and provide insights: {data}"
            analysis = await self.chat(prompt)
            await self.update_state(analyses_run=self.state.get("analyses_run", 0) + 1)
            return {"analysis": analysis}

        if task == "summarize":
            text = payload.get("text", "")
            summary = await self.chat(f"Summarize: {text}")
            return {"summary": summary}

        return {"error": f"Unknown task: {task}"}


@app.route("/agent/<agent_id>", methods=["POST"])
def handle_agent(agent_id: str):
    body = request.get_json()

    agent = AnalystAgent(agent_id)
    result = asyncio.run(agent.handle_request({
        "action": body.get("action", "chat"),
        "message": body.get("message", ""),
        "payload": body.get("payload", {})
    }))

    return jsonify(result)


@app.route("/agent/<agent_id>/state", methods=["GET"])
def get_agent_state(agent_id: str):
    agent = AnalystAgent(agent_id)
    result = asyncio.run(agent.handle_request({"action": "state"}))
    return jsonify(result)


if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8080))
    app.run(host="0.0.0.0", port=port)
```
  </Tab>
</Tabs>

## Custom Storage Backends

Serverless environments often need external storage. Here are production-ready examples:

<Tabs>
  <Tab title="DynamoDB">
```python
import json
import boto3
from ai_query import Storage

class DynamoDBStorage:
    def __init__(self, table_name: str = "agents"):
        self._table = boto3.resource("dynamodb").Table(table_name)

    async def get(self, key: str):
        response = self._table.get_item(Key={"pk": key})
        item = response.get("Item")
        return json.loads(item["value"]) if item else None

    async def set(self, key: str, value):
        self._table.put_item(Item={"pk": key, "value": json.dumps(value)})

    async def delete(self, key: str):
        self._table.delete_item(Key={"pk": key})

    async def keys(self, prefix: str = "") -> list[str]:
        response = self._table.scan(
            FilterExpression="begins_with(pk, :prefix)",
            ExpressionAttributeValues={":prefix": prefix}
        )
        return [item["pk"] for item in response.get("Items", [])]


# Usage
from ai_query import Agent, openai

agent = Agent(
    "my-agent",
    model=openai("gpt-4o"),
    storage=DynamoDBStorage("my-agents-table")
)
```

**DynamoDB Table Schema:**
```
Partition Key: pk (String)
```
  </Tab>

  <Tab title="Redis">
```python
import json
import redis.asyncio as redis
from ai_query import Storage

class RedisStorage:
    def __init__(self, url: str = "redis://localhost:6379", ttl: int = 86400 * 7):
        self._client = redis.from_url(url)
        self._ttl = ttl

    async def get(self, key: str):
        data = await self._client.get(key)
        return json.loads(data) if data else None

    async def set(self, key: str, value):
        await self._client.setex(key, self._ttl, json.dumps(value))

    async def delete(self, key: str):
        await self._client.delete(key)

    async def keys(self, prefix: str = "") -> list[str]:
        return [k.decode() for k in await self._client.keys(f"{prefix}*")]


# Usage
from ai_query import Agent, openai

agent = Agent(
    "my-agent",
    model=openai("gpt-4o"),
    storage=RedisStorage("redis://my-redis-host:6379")
)
```
  </Tab>

  <Tab title="PostgreSQL">
```python
import json
import asyncpg

class PostgreSQLStorage:
    def __init__(self, dsn: str):
        self._dsn = dsn
        self._pool = None

    async def _get_pool(self):
        if self._pool is None:
            self._pool = await asyncpg.create_pool(self._dsn, min_size=1, max_size=5)
            async with self._pool.acquire() as conn:
                await conn.execute("""
                    CREATE TABLE IF NOT EXISTS agent_storage (
                        key TEXT PRIMARY KEY,
                        value JSONB NOT NULL,
                        updated_at TIMESTAMPTZ DEFAULT NOW()
                    )
                """)
        return self._pool

    async def get(self, key: str):
        pool = await self._get_pool()
        async with pool.acquire() as conn:
            row = await conn.fetchrow(
                "SELECT value FROM agent_storage WHERE key = $1", key
            )
            return json.loads(row["value"]) if row else None

    async def set(self, key: str, value):
        pool = await self._get_pool()
        async with pool.acquire() as conn:
            await conn.execute("""
                INSERT INTO agent_storage (key, value, updated_at)
                VALUES ($1, $2, NOW())
                ON CONFLICT (key) DO UPDATE SET value = $2, updated_at = NOW()
            """, key, json.dumps(value))

    async def delete(self, key: str):
        pool = await self._get_pool()
        async with pool.acquire() as conn:
            await conn.execute("DELETE FROM agent_storage WHERE key = $1", key)

    async def keys(self, prefix: str = "") -> list[str]:
        pool = await self._get_pool()
        async with pool.acquire() as conn:
            rows = await conn.fetch(
                "SELECT key FROM agent_storage WHERE key LIKE $1", f"{prefix}%"
            )
            return [row["key"] for row in rows]


# Usage
from ai_query import Agent, openai

agent = Agent(
    "my-agent",
    model=openai("gpt-4o"),
    storage=PostgreSQLStorage("postgresql://user:pass@host/db")
)
```
  </Tab>
</Tabs>

## Multi-Agent Orchestration

Build complex workflows by having agents call each other via HTTP:

```python
# orchestrator.py
import httpx
from ai_query import Agent, SQLiteStorage, openai

class OrchestratorAgent(Agent):
    def __init__(self, agent_id: str):
        super().__init__(
            agent_id,
            model=openai("gpt-4o"),
            system="You coordinate tasks between specialized agents.",
            storage=SQLiteStorage("./orchestrator.db"),
            initial_state={"tasks_completed": 0}
        )

    async def handle_invoke(self, payload: dict) -> dict:
        task = payload.get("task")

        if task == "research_and_summarize":
            topic = payload.get("topic")

            async with httpx.AsyncClient() as client:
                # Call researcher agent
                research_result = await client.post(
                    "https://api.example.com/agent/researcher",
                    json={
                        "action": "invoke",
                        "payload": {"task": "research", "topic": topic}
                    }
                )
                research_data = research_result.json()

                # Call summarizer agent
                summary_result = await client.post(
                    "https://api.example.com/agent/summarizer",
                    json={
                        "action": "invoke",
                        "payload": {
                            "task": "summarize",
                            "text": research_data["result"]["findings"]
                        }
                    }
                )
                summary_data = summary_result.json()

            await self.update_state(
                tasks_completed=self.state.get("tasks_completed", 0) + 1
            )

            return {
                "topic": topic,
                "research": research_data["result"],
                "summary": summary_data["result"]["summary"]
            }

        return {"error": f"Unknown task: {task}"}
```

## Best Practices

### Cold Start Optimization

```python
# Initialize expensive resources at module level
import boto3

# These are initialized once per cold start
dynamodb = boto3.resource("dynamodb")
agents_table = dynamodb.Table("agents")

class OptimizedStorage:
    def __init__(self):
        self._table = agents_table  # Reuse module-level reference
```

### Connection Pooling

```python
# For PostgreSQL - reuse connection pool across requests
_pool = None

async def get_pool():
    global _pool
    if _pool is None:
        _pool = await asyncpg.create_pool(DATABASE_URL, min_size=1, max_size=10)
    return _pool
```

### Error Handling

```python
from fastapi import FastAPI, HTTPException
import asyncio

app = FastAPI()

@app.post("/agent/{agent_id}/chat")
async def chat(agent_id: str, message: str):
    try:
        agent = MyAgent(agent_id)
        result = await agent.handle_request({
            "action": "chat",
            "message": message
        })
        return result
    except asyncio.TimeoutError:
        raise HTTPException(status_code=504, detail="Agent timed out")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

### Timeout Configuration

```python
import asyncio

async def handler(request):
    agent = MyAgent(agent_id)

    # Wrap in timeout for Lambda/Cloud Run limits
    try:
        result = await asyncio.wait_for(
            agent.handle_request(request),
            timeout=25.0  # Leave buffer for Lambda's 30s limit
        )
        return result
    except asyncio.TimeoutError:
        return {"error": "Request timed out"}
```

## Next Steps

<CardGroup cols={2}>
  <Card title="Agent Communication" icon="messages" href="/cookbook/agent-communication">
    Make agents call each other
  </Card>
  <Card title="Multi-Agent Server" icon="server" href="/core/agent-server">
    Run multiple agents on one server
  </Card>
  <Card title="Custom Backends" icon="database" href="/api-reference/agent-backends#creating-custom-storage-backends">
    Build your own storage backend
  </Card>
  <Card title="Agent API Reference" icon="book" href="/api-reference/agent">
    Full Agent class documentation
  </Card>
</CardGroup>
